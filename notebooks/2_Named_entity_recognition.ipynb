{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a2da87",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "- For a given word and its context window, estimate whether the given word is location or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11619f5d",
   "metadata": {},
   "source": [
    "# 1. Download dataset\n",
    "- CoNLL2003 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a4faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-21 14:51:30--  https://data.deepai.org/conll2003.zip\n",
      "Resolving data.deepai.org (data.deepai.org)... 138.199.9.104, 2400:52e0:1a01::954:1\n",
      "Connecting to data.deepai.org (data.deepai.org)|138.199.9.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 982975 (960K) [application/zip]\n",
      "Saving to: ‘conll2003.zip’\n",
      "\n",
      "conll2003.zip       100%[===================>] 959.94K  1.11MB/s    in 0.8s    \n",
      "\n",
      "2023-03-21 14:51:31 (1.11 MB/s) - ‘conll2003.zip’ saved [982975/982975]\n",
      "\n",
      "Archive:  conll2003.zip\n",
      "  inflating: metadata                \n",
      "  inflating: test.txt                \n",
      "  inflating: train.txt               \n",
      "  inflating: valid.txt               \n"
     ]
    }
   ],
   "source": [
    "!wget https://data.deepai.org/conll2003.zip # Download dataset\n",
    "!unzip conll2003.zip # Unzip dataset zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643dde5",
   "metadata": {},
   "source": [
    "## 2. Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31874b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'s POS B-NP O\",\n",
       " 'representative NN I-NP O',\n",
       " 'to TO B-PP O',\n",
       " 'the DT B-NP O',\n",
       " 'European NNP I-NP B-ORG',\n",
       " 'Union NNP I-NP I-ORG',\n",
       " \"'s POS B-NP O\",\n",
       " 'veterinary JJ I-NP O',\n",
       " 'committee NN I-NP O',\n",
       " 'Werner NNP I-NP B-PER',\n",
       " 'Zwingmann NNP I-NP I-PER',\n",
       " 'said VBD B-VP O',\n",
       " 'on IN B-PP O',\n",
       " 'Wednesday NNP B-NP O',\n",
       " 'consumers NNS I-NP O',\n",
       " 'should MD B-VP O',\n",
       " 'buy VB I-VP O',\n",
       " 'sheepmeat NN B-NP O',\n",
       " 'from IN B-PP O',\n",
       " 'countries NNS B-NP O',\n",
       " 'other JJ B-ADJP O',\n",
       " 'than IN B-PP O',\n",
       " 'Britain NNP B-NP B-LOC',\n",
       " 'until IN B-SBAR O',\n",
       " 'the DT B-NP O',\n",
       " 'scientific JJ I-NP O',\n",
       " 'advice NN I-NP O',\n",
       " 'was VBD B-VP O',\n",
       " 'clearer JJR B-ADJP O',\n",
       " '. . O O']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"train.txt\") as f:\n",
    "  string = ''.join(f.readlines())\n",
    "dataset = string.split('\\n')\n",
    "\n",
    "dataset[50:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e7f34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-DOCSTART- -X- -X- O'],\n",
       " ['EU NNP B-NP B-ORG',\n",
       "  'rejects VBZ B-VP O',\n",
       "  'German JJ B-NP B-MISC',\n",
       "  'call NN I-NP O',\n",
       "  'to TO B-VP O',\n",
       "  'boycott VB I-VP O',\n",
       "  'British JJ B-NP B-MISC',\n",
       "  'lamb NN I-NP O',\n",
       "  '. . O O'],\n",
       " ['Peter NNP B-NP B-PER', 'Blackburn NNP I-NP I-PER'],\n",
       " ['BRUSSELS NNP B-NP B-LOC', '1996-08-22 CD I-NP O'],\n",
       " ['The DT B-NP O',\n",
       "  'European NNP I-NP B-ORG',\n",
       "  'Commission NNP I-NP I-ORG',\n",
       "  'said VBD B-VP O',\n",
       "  'on IN B-PP O',\n",
       "  'Thursday NNP B-NP O',\n",
       "  'it PRP B-NP O',\n",
       "  'disagreed VBD B-VP O',\n",
       "  'with IN B-PP O',\n",
       "  'German JJ B-NP B-MISC',\n",
       "  'advice NN I-NP O',\n",
       "  'to TO B-PP O',\n",
       "  'consumers NNS B-NP O',\n",
       "  'to TO B-VP O',\n",
       "  'shun VB I-VP O',\n",
       "  'British JJ B-NP B-MISC',\n",
       "  'lamb NN I-NP O',\n",
       "  'until IN B-SBAR O',\n",
       "  'scientists NNS B-NP O',\n",
       "  'determine VBP B-VP O',\n",
       "  'whether IN B-SBAR O',\n",
       "  'mad JJ B-NP O',\n",
       "  'cow NN I-NP O',\n",
       "  'disease NN I-NP O',\n",
       "  'can MD B-VP O',\n",
       "  'be VB I-VP O',\n",
       "  'transmitted VBN I-VP O',\n",
       "  'to TO B-PP O',\n",
       "  'sheep NN B-NP O',\n",
       "  '. . O O']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "dataset_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
    "dataset_in_sentence[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c29a2a",
   "metadata": {},
   "source": [
    "### 2.1 Make Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4d1fbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The DT B-NP O', 'European NNP I-NP B-ORG', 'Commission NNP I-NP I-ORG', 'said VBD B-VP O', 'on IN B-PP O', 'Thursday NNP B-NP O', 'it PRP B-NP O', 'disagreed VBD B-VP O', 'with IN B-PP O', 'German JJ B-NP B-MISC', 'advice NN I-NP O', 'to TO B-PP O', 'consumers NNS B-NP O', 'to TO B-VP O', 'shun VB I-VP O', 'British JJ B-NP B-MISC', 'lamb NN I-NP O', 'until IN B-SBAR O', 'scientists NNS B-NP O', 'determine VBP B-VP O', 'whether IN B-SBAR O', 'mad JJ B-NP O', 'cow NN I-NP O', 'disease NN I-NP O', 'can MD B-VP O', 'be VB I-VP O', 'transmitted VBN I-VP O', 'to TO B-PP O', 'sheep NN B-NP O', '. . O O']\n",
      "['PAD', 'PAD', 'the', 'european', 'commission']\n"
     ]
    }
   ],
   "source": [
    "window_size = 2 \n",
    "sentence = dataset_in_sentence[4]\n",
    "word_idx = 0\n",
    "center_word = sentence[2].split(' ')[0]\n",
    "\n",
    "# from word_idx - window_length until word_idx + window_length\n",
    "def get_words_window(sentence, word_idx, window_size):\n",
    "  idx_range = range( max(word_idx-window_size, 0), min(word_idx+window_size+1, len(sentence)))\n",
    "  windowed_words = [sentence[idx].split(' ')[0].lower() for idx in idx_range]\n",
    "  \n",
    "  if word_idx < window_size:\n",
    "    windowed_words = ['PAD'] * (window_size-word_idx) + windowed_words\n",
    "  if word_idx + window_size >= len(sentence):\n",
    "    windowed_words += ['PAD'] * (word_idx + window_size -len(sentence)+1)\n",
    "  \n",
    "  assert len(windowed_words) == 1+window_size*2, \"The length of output has to follow window size\"\n",
    "  return windowed_words\n",
    "\n",
    "print(sentence)\n",
    "print(get_words_window(sentence, word_idx, window_size))\n",
    "# center_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c52b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "wrd2vec = gensim.downloader.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a0f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PAD', 'PAD', 'the', 'european', 'commission']\n",
      "the [ 0.04656    0.21318   -0.0074364 -0.45854   -0.035639   0.23643\n",
      " -0.28836    0.21521   -0.13486   -1.6413   ]\n",
      "european [ 0.37636   0.1245    0.13028   0.024309  0.50706   0.18205  -0.44874\n",
      "  0.35522   0.27065  -2.2199  ]\n",
      "commission [ 4.7286e-01 -3.9634e-01 -2.6584e-01  1.2371e-02 -2.5906e-01 -2.5823e-01\n",
      "  1.1492e-01 -1.4363e-01  2.0568e-03 -2.2627e+00]\n"
     ]
    }
   ],
   "source": [
    "word_idx = 0\n",
    "words_window = get_words_window(sentence, word_idx, window_size)\n",
    "print(words_window)\n",
    "for word in words_window:\n",
    "  if word in wrd2vec:\n",
    "    print(word , wrd2vec[word][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a6bd62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1451512/4286083826.py:7: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  concat_vector.append(torch.Tensor(wrd2vec[word]))\n"
     ]
    }
   ],
   "source": [
    "# concat vectors\n",
    "import torch\n",
    "\n",
    "concat_vector = []\n",
    "for word in words_window:\n",
    "  if word in wrd2vec:\n",
    "    concat_vector.append(torch.Tensor(wrd2vec[word]))\n",
    "  else:\n",
    "    zero_vector = torch.zeros(300)\n",
    "    concat_vector.append(zero_vector)\n",
    "\n",
    "concat_tensor = torch.cat(concat_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a52c7369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_flattened_vector_for_words_window(words_window):\n",
    "  '''\n",
    "  words_window (list): A list of words, with length 1+window_size*2\n",
    "  '''\n",
    "  output = [torch.Tensor(wrd2vec[word]) if word in wrd2vec else torch.zeros(300) for word in words_window ]\n",
    "  \n",
    "  return torch.cat(output)\n",
    "\n",
    "'''\n",
    "If you want to compare two tensors, and make sure those two tensors are exactly same (for every dimension)\n",
    "you can use abooltensor.all()\n",
    "'''\n",
    "bool_tensor = concat_tensor == make_flattened_vector_for_words_window(words_window)\n",
    "bool_tensor.all()\n",
    "# (concat_tensor == make_flattened_vector_for_words_window(words_window)).all()\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401cc7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5cc5ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n[300 300 300 300 300]\\n1500 \\n\\nconcat_tensor's 1200th dimension\\n= 0th dimension of the 4th word\\n\\nconcat_tensor's 50th dimension\\n= 50th dimension of the 0th word\\n\\nconcat_tensor's 350th dimension\\n= 50th dimension of the 1st word\\n\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_tensor = torch.cat(concat_vector)\n",
    "\n",
    "print(concat_tensor[650] == concat_vector[2][49])\n",
    "'''\n",
    "[300 300 300 300 300]\n",
    "1500 \n",
    "\n",
    "concat_tensor's 1200th dimension\n",
    "= 0th dimension of the 4th word\n",
    "\n",
    "concat_tensor's 50th dimension\n",
    "= 50th dimension of the 0th word\n",
    "\n",
    "concat_tensor's 350th dimension\n",
    "= 50th dimension of the 1st word\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89c74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "hidden_size = 128\n",
    "first_layer = nn.Linear(300*5, 128, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62884d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1500])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee1beaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b2d23ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1500]), torch.Size([128]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = first_layer(concat_tensor)\n",
    "concat_tensor.shape, hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1772c2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0682, -0.0923, -0.0940,  0.0756, -0.0175, -0.3025,  0.0945, -0.2570,\n",
       "        -0.0983, -0.1161,  0.1883, -0.0350,  0.4268, -0.2735, -0.1689,  0.0428,\n",
       "        -0.1761, -0.0236,  0.0563,  0.0217,  0.0363,  0.0156,  0.0044, -0.0684,\n",
       "        -0.0430,  0.0631,  0.2835,  0.0891,  0.1542,  0.0012, -0.1917, -0.3575,\n",
       "         0.0321, -0.1149,  0.0270,  0.1977,  0.1497,  0.1066, -0.0751, -0.1109,\n",
       "        -0.2169,  0.3070, -0.0943, -0.1034, -0.2323, -0.1022,  0.1495,  0.1178,\n",
       "         0.1320,  0.0252,  0.1438,  0.0259,  0.0027, -0.2526,  0.2652,  0.0737,\n",
       "        -0.0136, -0.0559, -0.0364,  0.0574,  0.0576,  0.0747,  0.1169, -0.0582,\n",
       "        -0.0546,  0.2745, -0.0195,  0.0427,  0.0931,  0.2615,  0.0027,  0.2862,\n",
       "         0.0875, -0.1327,  0.0058, -0.1183,  0.0258, -0.0506, -0.1921, -0.3698,\n",
       "         0.1010, -0.2236, -0.0598,  0.0293, -0.0462,  0.0794, -0.0231,  0.1567,\n",
       "         0.0183, -0.0155, -0.1726,  0.2906, -0.0280, -0.0679, -0.1953, -0.1351,\n",
       "         0.1173,  0.2281,  0.1474, -0.3652, -0.1338, -0.1366,  0.0730,  0.0415,\n",
       "        -0.0837, -0.0380, -0.1533, -0.0966, -0.0699,  0.0241,  0.1150, -0.3845,\n",
       "         0.1870,  0.0967, -0.1095, -0.0138,  0.1518,  0.0985,  0.0776, -0.0763,\n",
       "         0.3787,  0.1864, -0.0199, -0.0136, -0.0413,  0.1356,  0.0373, -0.0134],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wx = torch.matmul(first_layer.weight, concat_tensor) \n",
    "b = first_layer.bias\n",
    "\n",
    "wx+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cd5e5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0682, -0.0923, -0.0940,  0.0756, -0.0175, -0.3025,  0.0945, -0.2570,\n",
       "        -0.0983, -0.1161,  0.1883, -0.0350,  0.4268, -0.2735, -0.1689,  0.0428,\n",
       "        -0.1761, -0.0236,  0.0563,  0.0217,  0.0363,  0.0156,  0.0044, -0.0684,\n",
       "        -0.0430,  0.0631,  0.2835,  0.0891,  0.1542,  0.0012, -0.1917, -0.3575,\n",
       "         0.0321, -0.1149,  0.0270,  0.1977,  0.1497,  0.1066, -0.0751, -0.1109,\n",
       "        -0.2169,  0.3070, -0.0943, -0.1034, -0.2323, -0.1022,  0.1495,  0.1178,\n",
       "         0.1320,  0.0252,  0.1438,  0.0259,  0.0027, -0.2526,  0.2652,  0.0737,\n",
       "        -0.0136, -0.0559, -0.0364,  0.0574,  0.0576,  0.0747,  0.1169, -0.0582,\n",
       "        -0.0546,  0.2745, -0.0195,  0.0427,  0.0931,  0.2615,  0.0027,  0.2862,\n",
       "         0.0875, -0.1327,  0.0058, -0.1183,  0.0258, -0.0506, -0.1921, -0.3698,\n",
       "         0.1010, -0.2236, -0.0598,  0.0293, -0.0462,  0.0794, -0.0231,  0.1567,\n",
       "         0.0183, -0.0155, -0.1726,  0.2906, -0.0280, -0.0679, -0.1953, -0.1351,\n",
       "         0.1173,  0.2281,  0.1474, -0.3652, -0.1338, -0.1366,  0.0730,  0.0415,\n",
       "        -0.0837, -0.0380, -0.1533, -0.0966, -0.0699,  0.0241,  0.1150, -0.3845,\n",
       "         0.1870,  0.0967, -0.1095, -0.0138,  0.1518,  0.0985,  0.0776, -0.0763,\n",
       "         0.3787,  0.1864, -0.0199, -0.0136, -0.0413,  0.1356,  0.0373, -0.0134],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer(concat_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af99d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1500])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0234, -0.0016,  0.0245,  ..., -0.0140,  0.0228,  0.0244],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(first_layer.weight.shape)\n",
    "first_layer.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86ab205d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entire_output = []\n",
    "for neuron in first_layer.weight:\n",
    "  entire_output.append((neuron * concat_tensor).sum())\n",
    "# entire_output\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b03c750c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD', 'PAD', 'the', 'european', 'commission']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6dbee12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8404e-02, -3.4393e-03,  1.2680e-02,  1.0789e-02,  2.4724e-02,\n",
       "         2.0654e-02, -4.6074e-03,  9.9631e-03, -1.1547e-02,  2.5176e-02,\n",
       "         9.3105e-03,  2.0875e-02,  6.1576e-03,  1.3280e-03, -1.9320e-02,\n",
       "         3.2641e-03,  1.0713e-03, -2.1077e-02, -1.3388e-02,  1.6420e-02,\n",
       "        -8.8603e-03,  1.2601e-02, -2.4617e-02, -1.7217e-03, -1.4043e-02,\n",
       "         2.2048e-02, -7.0111e-03,  3.1020e-03,  1.4639e-02,  2.2705e-02,\n",
       "         5.4842e-03, -1.6591e-02, -1.6450e-02, -2.2884e-02,  1.3556e-03,\n",
       "        -1.9342e-02, -3.0844e-03,  1.2723e-02,  1.0531e-02, -8.8435e-03,\n",
       "         1.2381e-02, -6.8721e-03,  7.5555e-03,  1.1064e-02,  1.5248e-02,\n",
       "         2.1598e-02, -1.4893e-02,  2.0339e-02, -5.3582e-03,  2.4540e-02,\n",
       "         9.8794e-03, -1.5995e-03, -6.6877e-03,  1.7079e-02,  3.4734e-03,\n",
       "         2.2441e-03, -1.3161e-02, -2.0857e-02,  2.2771e-03, -2.4354e-03,\n",
       "         1.9574e-02, -2.3609e-02,  4.6484e-04, -1.3442e-03, -2.5218e-02,\n",
       "         3.1336e-03, -1.0709e-03, -2.7058e-03,  1.1269e-02,  1.6376e-02,\n",
       "        -5.6799e-03, -1.0760e-02,  1.5046e-02, -2.0044e-02,  1.0390e-02,\n",
       "        -2.2913e-02,  4.3005e-03,  1.4411e-02, -6.9677e-03,  1.8531e-02,\n",
       "        -5.6630e-03, -2.4498e-02, -1.0629e-02, -1.9634e-02, -1.1434e-02,\n",
       "        -2.7090e-03, -1.7934e-02, -1.0526e-02,  1.5943e-02,  1.5836e-02,\n",
       "        -2.1837e-02, -8.5131e-03, -6.6949e-03, -1.5462e-02,  2.5603e-02,\n",
       "        -1.6212e-02, -1.4360e-02,  5.2123e-03,  7.9710e-03,  1.9979e-02,\n",
       "         2.2785e-02, -8.7387e-04,  5.0833e-03,  5.6575e-03, -1.2585e-02,\n",
       "         5.6108e-05,  6.8710e-03,  2.0651e-03, -4.8565e-03,  2.1140e-02,\n",
       "        -1.7278e-02, -1.4110e-02, -2.5588e-02, -1.8632e-02, -6.9808e-04,\n",
       "        -1.3517e-03, -9.4599e-03,  1.1345e-02, -2.0940e-02,  6.4844e-03,\n",
       "        -3.0632e-03,  1.2351e-02, -2.1026e-02,  2.4543e-02, -2.0213e-02,\n",
       "         1.6872e-02, -1.9031e-02,  2.1486e-02, -2.3305e-02,  7.8264e-03,\n",
       "         3.5267e-03, -1.2409e-02,  1.0925e-02, -1.6938e-02, -2.3004e-02,\n",
       "         1.9440e-02, -2.1305e-02,  1.2343e-02,  2.4944e-02, -1.7160e-02,\n",
       "        -2.4338e-02,  2.1103e-02, -1.7935e-02, -1.1369e-03, -1.2694e-02,\n",
       "         1.4929e-02,  4.5850e-03,  5.7325e-04, -2.0888e-02, -1.8908e-02,\n",
       "         1.1299e-02,  2.9103e-03,  1.9055e-02,  2.0394e-02, -2.4382e-02,\n",
       "         1.4680e-02,  1.5490e-02,  2.2962e-03, -2.1041e-02,  1.0880e-02,\n",
       "         3.5470e-03, -1.5568e-02,  1.3308e-02,  2.7859e-03, -2.5045e-02,\n",
       "        -2.6033e-03,  9.5817e-03,  1.9196e-02,  2.0776e-02, -7.3691e-03,\n",
       "        -1.8074e-02,  2.0320e-02, -1.7206e-02,  7.2160e-03, -1.9831e-02,\n",
       "         1.6955e-02,  1.5477e-02,  4.1914e-03, -7.6739e-03, -1.0488e-04,\n",
       "         2.2775e-02, -7.2760e-03,  2.3086e-02, -2.4670e-02, -2.0601e-02,\n",
       "         1.1496e-02,  2.4547e-02,  1.5697e-02,  2.3800e-03, -1.1265e-02,\n",
       "         2.5347e-02, -9.9673e-03,  8.9447e-03,  6.5219e-03,  1.1987e-02,\n",
       "         1.7288e-02, -2.3593e-02,  7.8635e-03, -1.9533e-02,  2.5477e-02,\n",
       "         4.5839e-03,  2.3947e-02, -8.6090e-03, -2.4771e-02, -2.5746e-02,\n",
       "        -1.5091e-02,  2.5133e-02, -3.0051e-03, -1.0800e-02, -6.5737e-03,\n",
       "        -1.4258e-02,  1.3900e-03,  1.2124e-02,  2.4758e-02, -2.6594e-03,\n",
       "         2.0526e-02,  2.9446e-03,  1.1201e-02, -1.6366e-02, -1.3348e-02,\n",
       "        -2.5409e-02,  2.5158e-02,  1.5671e-02,  2.4730e-02, -5.3425e-03,\n",
       "         1.7096e-02, -2.0084e-02,  5.2547e-03, -6.8736e-03,  6.1126e-03,\n",
       "         2.3024e-03,  2.5330e-02, -1.3289e-02,  2.7057e-03,  8.4278e-03,\n",
       "        -1.2352e-02, -1.6297e-02, -7.1020e-03,  1.7321e-02, -5.4258e-03,\n",
       "        -1.1198e-03,  1.4964e-02,  4.1031e-03,  1.6661e-02,  2.5061e-02,\n",
       "         1.3565e-02, -1.6040e-02,  1.1868e-03,  1.9319e-02,  9.9670e-03,\n",
       "        -5.5261e-03, -6.5468e-03, -6.0794e-03,  1.9682e-02, -1.4071e-02,\n",
       "         1.4916e-02, -5.6807e-03, -1.7750e-02,  1.1381e-02,  9.5076e-03,\n",
       "         1.9177e-02,  1.8468e-02,  1.7095e-02, -1.0956e-02,  6.6120e-03,\n",
       "         1.1023e-02, -1.9904e-04,  2.3618e-02,  2.0824e-02, -3.6555e-03,\n",
       "        -2.4372e-02,  2.6093e-03, -1.6578e-02,  3.3199e-04,  1.4494e-02,\n",
       "        -4.4196e-03,  3.9801e-03,  7.8229e-03,  2.3623e-02,  1.3186e-02,\n",
       "         1.2083e-02, -3.0356e-03, -1.8076e-02, -1.3250e-02, -8.3666e-03,\n",
       "        -1.5830e-02,  9.1000e-03, -1.4882e-03,  1.3352e-02,  5.7154e-03,\n",
       "         1.6021e-02, -1.2095e-02, -1.6358e-02, -2.0751e-02,  1.0067e-03,\n",
       "         6.4489e-03,  1.8187e-03, -7.6911e-03,  2.0633e-02,  7.6634e-04],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer.weight[0][600:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8347386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0682, -0.0923, -0.0940,  0.0756, -0.0175, -0.3025,  0.0945, -0.2570,\n",
       "         -0.0983, -0.1161,  0.1883, -0.0350,  0.4268, -0.2735, -0.1689,  0.0428,\n",
       "         -0.1761, -0.0236,  0.0563,  0.0217], grad_fn=<SliceBackward0>),\n",
       " tensor([0.0000, 0.0000, 0.0000, 0.0756, 0.0000, 0.0000, 0.0945, 0.0000, 0.0000,\n",
       "         0.0000, 0.1883, 0.0000, 0.4268, 0.0000, 0.0000, 0.0428, 0.0000, 0.0000,\n",
       "         0.0563, 0.0217], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = first_layer(concat_tensor)\n",
    "hidden_after_activation = torch.relu(hidden)\n",
    "hidden[:20], hidden_after_activation[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9794d994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac60ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_layer = nn.Linear(in_features=128, out_features=1, bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "944dd4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PAD', 'PAD', 'the', 'european', 'commission'],\n",
       " tensor([0.5187], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_output = second_layer(hidden_after_activation)\n",
    "final_prediction = torch.sigmoid(second_output)\n",
    "words_window, final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31b894da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.zeros(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1717281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD', 'PAD', 'the', 'european', 'commission']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_window(sentence, word_idx, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97b788b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The DT B-NP O',\n",
       " 'European NNP I-NP B-ORG',\n",
       " 'Commission NNP I-NP I-ORG',\n",
       " 'said VBD B-VP O',\n",
       " 'on IN B-PP O']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fffd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f8b574",
   "metadata": {},
   "source": [
    "## 3. Make a Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05ef02f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.NERModel'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4959], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NERModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.first_layer = nn.Linear(in_features=1500, out_features=128)\n",
    "    self.second_layer = nn.Linear(in_features=128, out_features=1)\n",
    "    \n",
    "  def forward(self, x):\n",
    "#     print(\"forward is called\")\n",
    "#     print(x)\n",
    "    hidden_representation = self.first_layer(x)\n",
    "    hidden_after_activation = torch.relu(hidden_representation)\n",
    "    scalar_value = self.second_layer(hidden_after_activation)\n",
    "    probability = torch.sigmoid(scalar_value)\n",
    "    return probability\n",
    "  \n",
    "\n",
    "model = NERModel()\n",
    "print(type(model))\n",
    "model(concat_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModelWord(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.first_word = nn.Linear(in_features=300, out_features=128)\n",
    "    self.second_word = nn.Linear(300, 128)\n",
    "    self.third_word = nn.Linear(300, 128)\n",
    "    self.fourth_word = nn.Linear(300, 128)\n",
    "    self.fifth_word = nn.Linear(300, 128)\n",
    "    \n",
    "    self.sixth_word = nn.Linear(300, 128)\n",
    "\n",
    "    self.first_layer = nn.Linear(in_features=1800, out_features=128)\n",
    "    self.second_layer = nn.Linear(in_features=128, out_features=1)\n",
    "    \n",
    "  def forward(self, x1, x2, x3, x4, x5):\n",
    "#     print(\"forward is called\")\n",
    "#     print(x)\n",
    "    \n",
    "    \n",
    "#     hidden_representation = self.first_layer(x)\n",
    "    hidden_representation = self.first_word(x1) + self.second_word(x2) ~ \n",
    "\n",
    "    hidden_after_activation = torch.relu(hidden_representation)\n",
    "    scalar_value = self.second_layer(hidden_after_activation)\n",
    "    probability = torch.sigmoid(scalar_value)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a3ba8",
   "metadata": {},
   "source": [
    "## 4. Implement a train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74b595af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor Epoch in NumEpochs:\\n  For DataSample in TrainingSet:\\n    TrainWithDataSample(Model, DataSample)\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For Epoch in NumEpochs:\n",
    "  For DataSample in TrainingSet:\n",
    "    TrainWithDataSample(Model, DataSample)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6750b643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The DT B-NP O',\n",
       " 'European NNP I-NP B-ORG',\n",
       " 'Commission NNP I-NP I-ORG',\n",
       " 'said VBD B-VP O',\n",
       " 'on IN B-PP O',\n",
       " 'Thursday NNP B-NP O',\n",
       " 'it PRP B-NP O',\n",
       " 'disagreed VBD B-VP O',\n",
       " 'with IN B-PP O',\n",
       " 'German JJ B-NP B-MISC',\n",
       " 'advice NN I-NP O',\n",
       " 'to TO B-PP O',\n",
       " 'consumers NNS B-NP O',\n",
       " 'to TO B-VP O',\n",
       " 'shun VB I-VP O',\n",
       " 'British JJ B-NP B-MISC',\n",
       " 'lamb NN I-NP O',\n",
       " 'until IN B-SBAR O',\n",
       " 'scientists NNS B-NP O',\n",
       " 'determine VBP B-VP O',\n",
       " 'whether IN B-SBAR O',\n",
       " 'mad JJ B-NP O',\n",
       " 'cow NN I-NP O',\n",
       " 'disease NN I-NP O',\n",
       " 'can MD B-VP O',\n",
       " 'be VB I-VP O',\n",
       " 'transmitted VBN I-VP O',\n",
       " 'to TO B-PP O',\n",
       " 'sheep NN B-NP O',\n",
       " '. . O O']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_in_sentence[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "936e1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d163bc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "-log(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dd30951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6560989022254944\n",
      "0.6399050354957581\n",
      "0.6489315032958984\n",
      "0.8474754691123962\n",
      "0.5633457899093628\n",
      "0.9032095074653625\n",
      "0.5906470417976379\n",
      "0.5854349136352539\n",
      "0.5068738460540771\n",
      "0.5365739464759827\n",
      "0.46314737200737\n",
      "0.47467195987701416\n",
      "0.5720842480659485\n",
      "0.3640608787536621\n",
      "0.2275027483701706\n",
      "0.3622237741947174\n",
      "0.30291855335235596\n",
      "0.21142800152301788\n",
      "1.108893632888794\n",
      "0.792802631855011\n",
      "0.23962511122226715\n",
      "0.6343240737915039\n",
      "0.48289063572883606\n",
      "0.839089572429657\n",
      "0.25012698769569397\n",
      "0.25959694385528564\n",
      "0.21995367109775543\n",
      "0.3456287086009979\n",
      "0.11637412011623383\n",
      "0.19501881301403046\n"
     ]
    }
   ],
   "source": [
    "model = NERModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "'''\n",
    "on-the-fly method to get a data sample\n",
    "'''\n",
    "for sentence in dataset_in_sentence[:30]:\n",
    "  for wrd_idx in range(len(sentence)):\n",
    "    words_window = get_words_window(sentence, wrd_idx, 2)\n",
    "    flattened_vector = make_flattened_vector_for_words_window(words_window)\n",
    "    prediction = model(flattened_vector)\n",
    "    \n",
    "    label = sentence[wrd_idx].split(' ')[-1] in ('B-LOC', 'I-LOC')\n",
    "    label_tensor = torch.Tensor([label]).float()\n",
    "    loss = loss_fn(prediction, label_tensor) # Calculate loss\n",
    "    loss.backward() # Backpropagate the loss to get the gradient\n",
    "    optimizer.step() # Update the parameters\n",
    "    optimizer.zero_grad() # Reset the gradient of the parameters\n",
    "    print(loss.item())\n",
    "#     print(prediction.item(), label_tensor, loss.item())\n",
    "#     print(words_window, prediction, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e534c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPrepare training data before we start the training stage\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Prepare training data before we start the training stage\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2868525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_in_sentence):\n",
    "  total_data_sample = []\n",
    "  for sentence in dataset_in_sentence[:100]:\n",
    "    for wrd_idx in range(len(sentence)):\n",
    "      words_window = get_words_window(sentence, wrd_idx, 2)\n",
    "      flattened_vector = make_flattened_vector_for_words_window(words_window)    \n",
    "      label = sentence[wrd_idx].split(' ')[-1] in ('B-LOC', 'I-LOC')\n",
    "      data_sample = (flattened_vector, label)\n",
    "      total_data_sample.append(data_sample)\n",
    "  return total_data_sample\n",
    "\n",
    "total_data_sample = prepare_dataset(dataset_in_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "166aae1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1529,\n",
       " (tensor([-0.4737, -0.1800, -0.4015,  ...,  1.0656, -0.0622,  0.4095]), False))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_data_sample), total_data_sample[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e753aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowWordDataset:\n",
    "  def __init__(self, txt_path):\n",
    "    \n",
    "    with open(txt_path) as f:\n",
    "      string = ''.join(f.readlines())\n",
    "    dataset = string.split('\\n')\n",
    "    self.data_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
    "    self.data_samples = self.prepare_entire_data_sample()\n",
    "    \n",
    "  def prepare_entire_data_sample(self):\n",
    "    total_data_sample = []\n",
    "    for sentence in self.data_in_sentence:\n",
    "      for wrd_idx in range(len(sentence)):\n",
    "        words_window = get_words_window(sentence, wrd_idx, 2)\n",
    "        flattened_vector = make_flattened_vector_for_words_window(words_window)    \n",
    "        label = sentence[wrd_idx].split(' ')[-1] in ('B-LOC', 'I-LOC')\n",
    "        data_sample = (flattened_vector, label, words_window)\n",
    "        total_data_sample.append(data_sample)\n",
    "    return total_data_sample\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.data_samples)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.data_samples[idx][:2]\n",
    "  \n",
    "dataset = WindowWordDataset('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "470e4f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204567"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37081654",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.0857,  0.1658, -0.7905,  ...,  0.0020,  0.7095,  0.2967]), False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5881a8a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7199,  0.0743,  0.3479,  ..., -0.4654, -0.1551,  0.4396],\n",
       "         [-0.3062,  0.0885,  0.0152,  ..., -0.0091, -0.0848, -0.0733],\n",
       "         [ 0.0466,  0.2132, -0.0074,  ..., -0.2441, -0.0308, -0.0318],\n",
       "         ...,\n",
       "         [-0.2413,  0.1513,  0.0168,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2887, -0.1602,  0.0302,  ..., -0.1604,  0.0467, -0.0706],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.1541,  0.4886,  0.1367]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def custom_collate_fn(raw_batch):\n",
    "  '''\n",
    "  collate raw batch (a list of tuple data sample)\n",
    "  '''\n",
    "  \n",
    "  input_vectors = []\n",
    "  labels = []\n",
    "  for data_sample in raw_batch:\n",
    "    input_vector = data_sample[0]\n",
    "    label = data_sample[1]\n",
    "    \n",
    "    input_vectors.append(input_vector)\n",
    "    labels.append(label)\n",
    "#   print(input_vectors)\n",
    "#   print(labels)\n",
    "  \n",
    "  input_tensor = torch.stack(input_vectors) # stack a list of tensor into a new dimension\n",
    "#   concat_tensor = torch.cat(input_vectors) # this concatenate to an existing dimension\n",
    "  label_tensor = torch.Tensor(labels)\n",
    "#   print(input_tensor.shape, concat_tensor.shape)\n",
    "  return input_tensor, label_tensor \n",
    "  \n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c127044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204560, 204567)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader) * train_loader.batch_size, len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9264472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204560"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "204567//16 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d29a6426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVanilla Gradient Descent\\n\\nweights -= weights.grad * lr\\n\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Vanilla Gradient Descent\n",
    "\n",
    "weights -= weights.grad * lr\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96791a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools \n",
    "model = NERModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=False, collate_fn=custom_collate_fn, drop_last=True)\n",
    "\n",
    "loss_record = []\n",
    "# num_epochs = 5\n",
    "num_iteration = 0\n",
    "target_num_iteration = 10000\n",
    "\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "for batch in itertools.cycle(train_loader):\n",
    "  input_tensor, label = batch # input_tensor = batch[0] // label = batch[1]\n",
    "  prediction = model(input_tensor)\n",
    "  loss = loss_fn(prediction, label.unsqueeze(1)) # Calculate loss\n",
    "  loss.backward() # Backpropagate the loss to get the gradient\n",
    "  optimizer.step() # Update the parameters\n",
    "  optimizer.zero_grad() # Reset the gradient of the parameters\n",
    "  loss_record.append(loss.item())\n",
    "  num_iteration += 1 \n",
    "  if num_iteration > target_num_iteration:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b411593b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2a96ad58e0>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56b7cb",
   "metadata": {},
   "source": [
    "## Calculate Accuracy\n",
    "- first, with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8c062fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "num_total_acc_pred = 0\n",
    "for batch in train_loader:\n",
    "  input_tensor, label = batch # input_tensor = batch[0] // label = batch[1]\n",
    "  prediction = model(input_tensor)\n",
    "  num_accurate_prediction = ((prediction[:,0] > threshold) == label ).sum()\n",
    "  num_total_acc_pred += num_accurate_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e6146872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9968)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_total_acc_pred / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966937c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "87166a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "24394355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0.0025,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0002,     0.0000,     0.0000,\n",
       "            1.0000,     0.0000,     0.0000,     0.0000],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.set_printoptions(sci_mode=False)\n",
    "threshold = 0.5\n",
    "short_pred = prediction[:16, 0]\n",
    "short_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc29b120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(short_pred > threshold).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7cfa7145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35ee9bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_accurate_pred = (short_pred > threshold).float() == label[:16]\n",
    "is_accurate_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "adc399ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of correct prediction\n",
    "is_accurate_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6939fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = WindowWordDataset('test.txt')\n",
    "test_loader = DataLoader(testset, batch_size=64, shuffle=False, collate_fn=custom_collate_fn, drop_last=False)\n",
    "threshold = 0.5\n",
    "num_total_acc_pred = 0\n",
    "for batch in test_loader:\n",
    "  input_tensor, label = batch # input_tensor = batch[0] // label = batch[1]\n",
    "  prediction = model(input_tensor)\n",
    "  num_accurate_prediction = ((prediction[:,0] > threshold) == label ).sum()\n",
    "  num_total_acc_pred += num_accurate_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2747e260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1950,  0.2041,  0.3530],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.2705, -0.1292, -0.0133],\n",
      "        ...,\n",
      "        [ 0.0644,  0.2420,  0.2520,  ..., -0.4491,  0.1715, -0.0750],\n",
      "        [ 0.0121,  0.0925, -0.3330,  ..., -0.2737, -0.0990, -0.7888],\n",
      "        [-0.0677,  0.0513, -0.4817,  ..., -0.5074, -0.2050, -0.0687]]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "  print(batch)\n",
    "  break\n",
    "\n",
    "# batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0852b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.1950,  0.2041,  0.3530],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.2705, -0.1292, -0.0133],\n",
       "         ...,\n",
       "         [ 0.0644,  0.2420,  0.2520,  ..., -0.4491,  0.1715, -0.0750],\n",
       "         [ 0.0121,  0.0925, -0.3330,  ..., -0.2737, -0.0990, -0.7888],\n",
       "         [-0.0677,  0.0513, -0.4817,  ..., -0.5074, -0.2050, -0.0687]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fadde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68dcf4f2",
   "metadata": {},
   "source": [
    "# Toy cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bee8fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-8.)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_word_vec = torch.Tensor([0.3, -0.2, 0.4])\n",
    "third_word_vec = torch.Tensor([-1, 0, 2])\n",
    "second_word_vec = torch.Tensor([-2, -1, 1])\n",
    "fourth_word_vec = torch.Tensor([-2, 1, 5])\n",
    "\n",
    "weight_for_first_wrd = torch.Tensor([0, 2, 1])\n",
    "weight_for_third_wrd = torch.Tensor([1, 2,-1])\n",
    "weight_for_second_wrd = torch.Tensor([-1, 3, -2])\n",
    "\n",
    "weight_for_fourth_wrd = torch.rand(3) \n",
    "\n",
    "\n",
    "(first_word_vec * weight_for_first_wrd).sum(), (second_word_vec * weight_for_second_wrd).sum(), (third_word_vec * weight_for_third_wrd).sum()\n",
    "activation_of_this_neuron = (first_word_vec * weight_for_first_wrd).sum() + (second_word_vec * weight_for_second_wrd).sum() + (third_word_vec * weight_for_third_wrd).sum()\n",
    "\n",
    "activation_of_this_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf9256d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-8.)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_vec = torch.cat([first_word_vec, second_word_vec, third_word_vec])\n",
    "concatenated_vec\n",
    "\n",
    "concatenated_weights = torch.cat([weight_for_first_wrd, weight_for_second_wrd, weight_for_third_wrd])\n",
    "\n",
    "(concatenated_vec * concatenated_weights).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5e18f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  2.,  1.,  1.,  2., -1., -1.,  3., -2.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c383d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9881)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_total_acc_pred / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce0efd",
   "metadata": {},
   "source": [
    "## 5. Make Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf2a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
